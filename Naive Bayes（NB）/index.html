<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="网络安全,黑客,JAVA安全,代码审计,渗透测试,入侵,SRC,扫描,WEB安全,移动安全,PHP">
    <meta name="description" content="蓝骨, langu.xyz">
    <meta name="author" content="langu_xyz">
    
        <title>
            
                Naive Bayes（NB） |
                    
                        langu_xyz
        </title>
        
<link rel="stylesheet" href="/css/style.css">

            <link rel="shortcut icon" href="/images/logo.jpeg">
                
<link rel="stylesheet" href="/css/font-awesome.min.css">

                    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"blog.langu.xyz","root":"/","language":"zh","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":false,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/logo.jpeg","favicon":"/images/logo.jpeg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":true,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg1.svg","description":null},"scroll":{"progress_bar":{"enable":true},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":true},"lazyload":{"enable":true},"version":"3.4.3"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>

                    <script>
                        var _hmt = _hmt || [];
                        (function() {
                          var hm = document.createElement("script");
                          hm.src = "https://hm.baidu.com/hm.js?1cd6e64ff252acf24b707985fcec8850";
                          var s = document.getElementsByTagName("script")[0]; 
                          s.parentNode.insertBefore(hm, s);
                        })();
                        </script>
                        
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="langu_xyz" type="application/atom+xml">
</head>
<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fas fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                    <a class="logo-title" href="/">
                        langu_xyz
                    </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class="" href="/" >
                                HOME
                            </a>
                        </li>
                        
                        <li class="menu-item">
                            <a class="" href="/archives" >
                                ARCHIVES
                            </a>
                        </li>
                        
                        <li class="menu-item">
                            <a class="" href="/tags/THINK/" >
                                THINK
                            </a>
                        </li>
                        
                        <li class="menu-item">
                            <a class="" href="/about" >
                                ABOUT
                            </a>
                        </li>
                        
                            
                                <li class="menu-item search search-popup-trigger">
                                    <i class="fas fa-search"></i>
                                </li>
                                
                                
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                    
                        <div class="icon-item menu-bar">
                            <div class="menu-bar-middle"></div>
                        </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class="" href="/" >
                        HOME
                    </a>
                </li>
                
                <li class="drawer-menu-item flex-center">
                    <a class="" href="/archives" >
                        ARCHIVES
                    </a>
                </li>
                
                <li class="drawer-menu-item flex-center">
                    <a class="" href="/tags/THINK/" >
                        THINK
                    </a>
                </li>
                
                <li class="drawer-menu-item flex-center">
                    <a class="" href="/about" >
                        ABOUT
                    </a>
                </li>
                
        </ul>
    </div>

    <div class="window-mask"></div>

</header>
        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">Naive Bayes（NB）</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/logo.jpeg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">langu_xyz</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;2019-07-28 21:00:00
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E5%AE%89%E5%85%A8%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">安全数据分析</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/ML/">ML</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>1.6k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>7 Mins</span>
        </span>
    
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h4 id="0x01-NB"><a href="#0x01-NB" class="headerlink" title="0x01 NB"></a>0x01 NB</h4><p>朴素：整个形式化的过程只做最原始、最简单的假设</p>
<p>优点</p>
<ul>
<li>数据较少情况下仍然有效</li>
<li>可以处理多类别问题</li>
</ul>
<p>缺点</p>
<ul>
<li>对于输入数据的处理方式比较敏感</li>
</ul>
<p>适用数据类型</p>
<ul>
<li>标称型</li>
</ul>
<h4 id="0x02-贝叶斯决策理论"><a href="#0x02-贝叶斯决策理论" class="headerlink" title="0x02 贝叶斯决策理论"></a>0x02 贝叶斯决策理论</h4><p>计算数据点属于每个类别的概率，并进行比较，选择具有最高概率的决策</p>
<p><strong>条件概率</strong></p>
<p>推导过程</p>
<p><img lazyload src="/images/loading.svg" data-src="15371937340058.jpg"></p>
<p><img lazyload src="/images/loading.svg" data-src="15371937397573.jpg"></p>
<p><img lazyload src="/images/loading.svg" data-src="15371937656472.jpg"></p>
<p><img lazyload src="/images/loading.svg" data-src="15371937826699.jpg"></p>
<p><img lazyload src="/images/loading.svg" data-src="15371937881588.jpg"></p>
<h4 id="0x03-构建文档分类器"><a href="#0x03-构建文档分类器" class="headerlink" title="0x03 构建文档分类器"></a>0x03 构建文档分类器</h4><p>两个假设</p>
<ul>
<li>特征之间相互独立（统计意义上的独立）</li>
<li>每个特征同等重要</li>
</ul>
<p><strong>word2vec</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">def loadDataSet():</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    测试数据</span><br><span class="line">    :return: </span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    postingList = [[&#x27;my&#x27;, &#x27;dog&#x27;, &#x27;has&#x27;, &#x27;flea&#x27;, &#x27;problems&#x27;, &#x27;help&#x27;, &#x27;please&#x27;],</span><br><span class="line">                 [&#x27;maybe&#x27;, &#x27;not&#x27;, &#x27;take&#x27;, &#x27;him&#x27;, &#x27;to&#x27;, &#x27;dog&#x27;, &#x27;park&#x27;, &#x27;stupid&#x27;],</span><br><span class="line">                 [&#x27;my&#x27;, &#x27;dalmation&#x27;, &#x27;is&#x27;, &#x27;so&#x27;, &#x27;cute&#x27;, &#x27;I&#x27;, &#x27;love&#x27;, &#x27;him&#x27;],</span><br><span class="line">                 [&#x27;stop&#x27;, &#x27;posting&#x27;, &#x27;stupid&#x27;, &#x27;worthless&#x27;, &#x27;garbage&#x27;],</span><br><span class="line">                 [&#x27;mr&#x27;, &#x27;licks&#x27;, &#x27;ate&#x27;, &#x27;my&#x27;, &#x27;steak&#x27;, &#x27;how&#x27;, &#x27;to&#x27;, &#x27;stop&#x27;, &#x27;him&#x27;],</span><br><span class="line">                 [&#x27;quit&#x27;, &#x27;buying&#x27;, &#x27;worthless&#x27;, &#x27;dog&#x27;, &#x27;food&#x27;, &#x27;stupid&#x27;]]</span><br><span class="line">    classVec = [0, 1, 0, 1, 0, 1]  #是否包含侮辱性词语，为1</span><br><span class="line">    return postingList, classVec</span><br><span class="line">                 </span><br><span class="line">def createVocabList(dataSet):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    创建dataSet的不重复词列表</span><br><span class="line">    :param dataSet: </span><br><span class="line">    :return: </span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    vocabSet = set([])</span><br><span class="line">    for document in dataSet:</span><br><span class="line">        vocabSet = vocabSet | set(document)</span><br><span class="line">    return list(vocabSet)</span><br><span class="line"></span><br><span class="line">def setOfWords2Vec(vocabList, inputSet):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    :param vocabList: 不重复词列表</span><br><span class="line">    :param inputSet: 某文档</span><br><span class="line">    :return: 文档向量</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    returnVec = [0]*len(vocabList) #创建一个长度和vocabList相等的全部为0的向量</span><br><span class="line">    for word in inputSet:</span><br><span class="line">        if word in vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] = 1</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;the word: %s is not in my Vocabulary!&quot; % word)</span><br><span class="line">    return returnVec #[0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</span><br></pre></td></tr></table></figure>

<p><strong>训练算法</strong></p>
<ul>
<li>从词向量计算概率</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for postdoc in postingList:</span><br><span class="line">    trainmat.append(setOfWords2Vec(vocablist, postdoc))</span><br></pre></td></tr></table></figure>
<p><img lazyload src="/images/loading.svg" data-src="15372608870667.jpg"></p>
<p>通过setOfWords2Vec方法对文档进行处理，返回文档向量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def trainNB0(trainMatrix,trainCategory):</span><br><span class="line">    numTrainDocs = len(trainMatrix) #6 文档矩阵的行数</span><br><span class="line">    numWords = len(trainMatrix[0]) #32 矩阵的长度</span><br><span class="line">    pAbusive = sum(trainCategory)/float(numTrainDocs) #3/6  文档属于侮辱类型的概率</span><br><span class="line">    p0Num = ones(numWords) #ones函数可以创建任意维度和元素个数的数组，其元素值均为1</span><br><span class="line">    p1Num = ones(numWords)</span><br><span class="line">    p0Denom = 0.0</span><br><span class="line">    p1Denom = 0.0</span><br><span class="line">    for i in range(numTrainDocs):</span><br><span class="line">        if trainCategory[i] == 1:</span><br><span class="line">            p1Num += trainMatrix[i] #如果标签为侮辱性的，则两个列表相加</span><br><span class="line">            p1Denom += sum(trainMatrix[i]) #侮辱性文档的词数相加</span><br><span class="line">        else:</span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += sum(trainMatrix[i])</span><br><span class="line">    #p1num：[2. 2. 1. 1. 1. 1. 2. 1. 1. 2. 2. 1. 1. 1. 4. 2. 3. 2. 1. 1. 1. 1. 2. 2.</span><br><span class="line"> 2. 2. 1. 1. 1. 2. 1. 3.]</span><br><span class="line">    #p1Demon：19.0</span><br><span class="line">    p1Vect = log(p1Num/p1Denom)          #将单个词的数目除以总词数得到条件概率</span><br><span class="line">    p0Vect = log(p0Num/p0Denom)</span><br><span class="line">    return p0Vect, p1Vect, pAbusive</span><br></pre></td></tr></table></figure>
<p><img lazyload src="/images/loading.svg" data-src="15372610382692.jpg"></p>
<p><code>概率向量</code>：在给定文档类别条件下词汇表中单词的出现概率<br><code>p0Vect</code>:正常文档的概率向量<br><code>p1Vect</code>:侮辱性文档概率向量<br><code>pAbusive</code>:侮辱文档的概率</p>
<ul>
<li>概率值为0问题</li>
</ul>
<p>利用贝叶斯分类器对文档进行分类时，要计算多个概率的乘积以获得文档属于某个类别的概率，即计算p(w0|1)p(w1|1)p(w2|1)。如果其中一个概率值为0，那么最后的乘积也为0。为降低 这种影响，可以将所有词的出现数初始化为1，并将分母初始化为2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p0Denom = 2.0</span><br><span class="line">p1Denom = 2.0</span><br></pre></td></tr></table></figure>

<ul>
<li>下溢出问题</li>
</ul>
<p>相乘许多很小的数，最后四舍五入后会得到0</p>
<p><code>p(w0|ci)*p(w1|ci)*...*p(w0|ci)</code> 取对数，得到<code>ln(p(w0|ci))+ln(p(w1|ci))+...+ln(p(w0|ci))</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p1Vect = log(p1Num/p1Denom)         </span><br><span class="line">p0Vect = log(p0Num/p0Denom)</span><br></pre></td></tr></table></figure>

<p><strong>测试算法</strong></p>
<p><img lazyload src="/images/loading.svg" data-src="15372632355434.jpg"></p>
<p><img lazyload src="/images/loading.svg" data-src="15372632623577.jpg"><br>的含义为给定w向量的基础上来自类别ci的概率是多少</p>
<p>p(ci)的概率为<code>pAbusive</code><br>接下来需要计算p(w|ci)，假设所有词都互相独立，即<br><code>p(w0,w1,w2..wN|ci)=p(w0|ci)p(w1|ci)p(w2|ci)...p(wN|ci)</code></p>
<p>因为P(w)P(ci)两者是一样的，可以忽略</p>
<p>因为<code>log(p(w|c)p(c)) = log(p(w|c)) + log(p(c))</code>，所以在classifyNB方法中求和</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    元素相乘</span><br><span class="line">    :param vec2Classify:要分类的向量</span><br><span class="line">    :param p0Vec:正常文档概率向量</span><br><span class="line">    :param p1Vec:侮辱文档概率向量</span><br><span class="line">    :param pClass1:侮辱文档的概率</span><br><span class="line">    :return:1 or 0</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    p1 = sum(vec2Classify * p1Vec) + log(pClass1)</span><br><span class="line">    p0 = sum(vec2Classify * p0Vec) + log(1.0 - pClass1)</span><br><span class="line">    if p1 &gt; p0:</span><br><span class="line">        return 1</span><br><span class="line">    else: </span><br><span class="line">        return 0</span><br></pre></td></tr></table></figure>

<p><strong>便利函数</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def testingNB():</span><br><span class="line">    listOPosts,listClasses = loadDataSet()</span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    trainMat=[]</span><br><span class="line">    for postinDoc in listOPosts:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    p0V,p1V,pAb = trainNB0(array(trainMat), array(listClasses))</span><br><span class="line">    testEntry = [&#x27;love&#x27;, &#x27;my&#x27;, &#x27;dalmation&#x27;]</span><br><span class="line">    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    print(testEntry, &#x27;classified as: &#x27;, classifyNB(thisDoc, p0V, p1V, pAb))</span><br><span class="line">    testEntry = [&#x27;stupid&#x27;, &#x27;garbage&#x27;]</span><br><span class="line">    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    print(testEntry, &#x27;classified as: &#x27;, classifyNB(thisDoc, p0V, p1V, pAb))</span><br></pre></td></tr></table></figure>

<p><img lazyload src="/images/loading.svg" data-src="15372709062992.jpg"></p>
<ul>
<li>词袋模型</li>
</ul>
<p>在词袋中，每个单词可以出现 多次，而在词集中，每个词只能出现一次</p>
<p>每当遇到一个单词时，词向量中的对应值会+1</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def bagOfWords2VecMN(vocabList, inputSet):</span><br><span class="line">    returnVec = [0]*len(vocabList)</span><br><span class="line">    for word in inputSet:</span><br><span class="line">        if word in vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] += 1</span><br><span class="line">    return returnVec</span><br></pre></td></tr></table></figure>


<h4 id="0x04-Action-1"><a href="#0x04-Action-1" class="headerlink" title="0x04 Action 1"></a>0x04 Action 1</h4><p>垃圾邮件判断</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">def textParse(bigString):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    简单分词处理</span><br><span class="line">    :param bigString: </span><br><span class="line">    :return: </span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    import re</span><br><span class="line">    listOfTokens = re.split(&#x27;\W*&#x27;, bigString)</span><br><span class="line">    return [tok.lower() for tok in listOfTokens if len(tok) &gt; 2] #取长度大于3，转化为小写</span><br><span class="line">    </span><br><span class="line">def spamTest():</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    数据输入</span><br><span class="line">    处理</span><br><span class="line">    分割</span><br><span class="line">    训练</span><br><span class="line">    测试</span><br><span class="line">    :return: </span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    docList=[]</span><br><span class="line">    classList = []</span><br><span class="line">    fullText = []</span><br><span class="line">    for i in range(1, 26):</span><br><span class="line">        wordList = textParse(open(&#x27;email/spam/%d.txt&#x27; % i, &#x27;rb&#x27;).read().decode(&#x27;GBK&#x27;, &#x27;ignore&#x27;))</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(1)</span><br><span class="line">        wordList = textParse(open(&#x27;email/ham/%d.txt&#x27; % i, &#x27;rb&#x27;).read().decode(&#x27;GBK&#x27;, &#x27;ignore&#x27;))</span><br><span class="line">        docList.append(wordList)</span><br><span class="line">        fullText.extend(wordList)</span><br><span class="line">        classList.append(0)</span><br><span class="line">    vocabList = createVocabList(docList) #创建不重复词表</span><br><span class="line">    trainingSet = list(range(50)) #[0, 1, 2, 3, 4, 5, 6, 7, 8...44, 45, 46, 47, 48, 49]</span><br><span class="line">    testSet=[]</span><br><span class="line">    for i in range(10): #随机选择10条数据作为测试集</span><br><span class="line">        randIndex = int(random.uniform(0, len(trainingSet)))</span><br><span class="line">        testSet.append(trainingSet[randIndex])</span><br><span class="line">        del(trainingSet[randIndex])  </span><br><span class="line">    trainMat = []</span><br><span class="line">    trainClasses = []</span><br><span class="line">    for docIndex in trainingSet: # 训练集</span><br><span class="line">        trainMat.append(bagOfWords2VecMN(vocabList, docList[docIndex])) #词袋模型，构建词向量</span><br><span class="line">        trainClasses.append(classList[docIndex])</span><br><span class="line">    p0V, p1V, pSpam = trainNB0(array(trainMat), array(trainClasses))</span><br><span class="line">    errorCount = 0</span><br><span class="line">    for docIndex in testSet: # 测试集</span><br><span class="line">        wordVector = bagOfWords2VecMN(vocabList, docList[docIndex])</span><br><span class="line">        if classifyNB(array(wordVector), p0V, p1V, pSpam) != classList[docIndex]:</span><br><span class="line">            errorCount += 1</span><br><span class="line">            print(&quot;classification error&quot;, docList[docIndex])</span><br><span class="line">    print(&#x27;the error rate is: &#x27;, float(errorCount)/len(testSet))</span><br></pre></td></tr></table></figure>





        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：Naive Bayes（NB）</li>
        <li>Post author：langu_xyz</li>
        <li>Create time：2019-07-28 21:00:00</li>
        <li>
            Post link：https://blog.langu.xyz/Naive Bayes（NB）/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/Decision%20Tree/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Decision Tree</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/Logistic%20Regression/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">Logistic Regression</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2016</span>&nbsp;-&nbsp;
            
            2023&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a target="_blank" rel="noopener" href="//langu.xyz">AboutME:langu_xyz</a>
        </div>
        <!--
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        -->
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.3</a>
        </div>
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        
            <li class="tools-item rss flex-center">
                <a class="flex-center"
                   href="/atom.xml"
                   target="_blank"
                >
                    <i class="fas fa-rss"></i>
                </a>
            </li>
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#0x01-NB"><span class="nav-text">0x01 NB</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#0x02-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E7%90%86%E8%AE%BA"><span class="nav-text">0x02 贝叶斯决策理论</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#0x03-%E6%9E%84%E5%BB%BA%E6%96%87%E6%A1%A3%E5%88%86%E7%B1%BB%E5%99%A8"><span class="nav-text">0x03 构建文档分类器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#0x04-Action-1"><span class="nav-text">0x04 Action 1</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>



    
<script src="/js/local-search.js"></script>




    
<script src="/js/code-copy.js"></script>




    
<script src="/js/lazyload.js"></script>



<div class="post-scripts pjax">
    
        
<script src="/js/left-side-toggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/toc.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax'
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            KEEP.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            KEEP.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            KEEP.refresh();
        });
    });
</script>



</body>
</html>
